#!/usr/bin/env python3
"""
åˆ†æå’Œæ•´ç†é¡¹ç›®ä¸­çš„ Markdown æ–‡æ¡£æ–‡ä»¶
"""

import os
import shutil
from pathlib import Path
from typing import Dict, List, Tuple
import re


# æ–‡æ¡£åˆ†ç±»è§„åˆ™
DOC_CATEGORIES = {
    "01_å¿«é€Ÿå¼€å§‹": [
        "README.md",
        "QUICKSTART.md",
        "QUICK_START.md",
        "QUICKSTART_PLAN_A.md",
        "GETTING_STARTED.md",
        "INDEX.md",
        "PROJECT_INDEX.md",
    ],
    "02_é…ç½®æŒ‡å—": [
        "CONFIG_GUIDE.md",
        "API_KEYS_REFERENCE.md",
        "BINANCE_IP_WHITELIST_GUIDE.md",
        "ENV_CONFIG.md",
    ],
    "03_æ¶æ„è®¾è®¡": [
        "ARCHITECTURE.md",
        "SYSTEM_SUMMARY.md",
        "PROJECT_SUMMARY.md",
        "FILE_MANIFEST.md",
    ],
    "04_å·¥ä½œæµç¨‹": [
        "WORKFLOW_GUIDE.md",
        "STRATEGY_DEVELOPMENT_GUIDE.md",
        "QUICKSTART_PLAN_A.md",
    ],
    "05_æ•°æ®ç®¡é“": [
        "DATA_PIPELINE.md",
        "DATA_FLOW_SUMMARY.md",
        "DATA_FLOW_INDEX.md",
        "DATA_FLOW_COMPLETION_REPORT.md",
        "DATA_FLOW_FIX_SUMMARY.md",
        "DATA_PIPELINE_VERIFICATION.md",
        "DATA_SOURCE_MIGRATION_GUIDE.md",
        "DATA_MIGRATION_SUCCESS_REPORT.md",
        "DATA_QUALITY_FIX_REPORT.md",
        "QUICK_DATA_VERIFICATION.md",
    ],
    "06_æ—¥å¿—ç³»ç»Ÿ": [
        "PIPELINE_LOG_GUIDE.md",
        "PIPELINE_LOG_INDEX.md",
        "PIPELINE_LOG_QUICKSTART.md",
        "PIPELINE_LOG_COMPLETE.md",
        "TRADE_LOGGING_GUIDE.md",
        "TRADE_LOGGING_COMPLETE.md",
        "LOGGER_USAGE_GUIDE.md",
        "LOG_JSON_ENHANCEMENT.md",
    ],
    "07_å®ç›˜äº¤æ˜“": [
        "LIVE_TRADING_QUICKSTART.md",
        "LIVE_TRADING_READY.md",
        "LIVE_TRADING_SUCCESS.md",
        "LIVE_TRADING_USAGE.md",
        "LIVE_TRADING_SAFETY_GUIDE.md",
        "FUTURES_TRADING_FIX_REPORT.md",
        "STOP_LOSS_TAKE_PROFIT_GUIDE.md",
    ],
    "08_æµ‹è¯•éªŒè¯": [
        "TRADING_LOGIC_VERIFICATION_CHECKLIST.md",
        "TRADING_LOGIC_VERIFICATION_CHECKLIST_PRODUCTION.md",
        "SYSTEM_TEST_REPORT.md",
        "COLOR_TEST_REPORT.md",
    ],
    "09_é¡¹ç›®æŠ¥å‘Š": [
        "PROJECT_COMPLETION_REPORT.md",
        "PROJECT_RUN_SUCCESS_REPORT.md",
        "FINAL_SUCCESS_REPORT.md",
        "FINAL_SUMMARY.md",
        "PLAN_A_SUCCESS_REPORT.md",
        "PLAN_A_FINAL_SUMMARY.md",
        "PLAN_A_CHECKLIST.md",
        "PLAN2_READY.md",
        "SESSION_SUMMARY.md",
        "DEPLOYMENT_STATUS.md",
    ],
    "10_é—®é¢˜ä¿®å¤": [
        "BUG_FIX_REPORT.md",
        "FIX_REPORT.md",
        "PROBLEM_ANALYSIS_REPORT.md",
        "FORMAT_FIX.md",
        "COLOR_OPTIMIZATION.md",
        "DEEPSEEK_QUALITY_COMPARISON.md",
        "FEATURE_ENHANCEMENT.md",
    ],
    "11_æ£€æŸ¥æ¸…å•": [
        "CHECKLIST.md",
    ],
    "12_å…¶ä»–": [],  # æœªåˆ†ç±»çš„æ–‡ä»¶
}


def analyze_md_file(file_path: Path) -> Dict:
    """åˆ†æå•ä¸ª Markdown æ–‡ä»¶"""
    info = {
        "name": file_path.name,
        "path": str(file_path),
        "size": file_path.stat().st_size,
        "lines": 0,
        "title": "",
        "category": None,
        "keywords": [],
    }
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            info["lines"] = len(lines)
            
            # æå–æ ‡é¢˜ï¼ˆå‰10è¡Œä¸­çš„ç¬¬ä¸€ä¸ª # æ ‡é¢˜ï¼‰
            for i, line in enumerate(lines[:10]):
                if line.strip().startswith('#'):
                    info["title"] = line.strip().lstrip('#').strip()
                    break
            
            # æå–å…³é”®è¯ï¼ˆä»æ ‡é¢˜å’Œå†…å®¹ä¸­ï¼‰
            content = ' '.join(lines[:50])  # å‰50è¡Œ
            keywords = re.findall(r'\b[A-Z][A-Z_]+\b', content)
            info["keywords"] = list(set(keywords))[:10]
    
    except Exception as e:
        info["error"] = str(e)
    
    return info


def categorize_file(filename: str) -> str:
    """æ ¹æ®æ–‡ä»¶ååˆ†ç±»"""
    for category, files in DOC_CATEGORIES.items():
        if filename in files:
            return category
    return "12_å…¶ä»–"


def organize_documents():
    """æ•´ç†æ–‡æ¡£"""
    project_root = Path(__file__).parent
    docs_dir = project_root / "docs_organized"
    
    # åˆ›å»ºæ•´ç†ç›®å½•
    if docs_dir.exists():
        print(f"âš ï¸  ç›®å½•å·²å­˜åœ¨: {docs_dir}")
        response = input("æ˜¯å¦åˆ é™¤å¹¶é‡æ–°åˆ›å»º? (y/n): ")
        if response.lower() == 'y':
            shutil.rmtree(docs_dir)
        else:
            print("å–æ¶ˆæ“ä½œ")
            return
    
    docs_dir.mkdir(exist_ok=True)
    
    # è¯¢é—®æ˜¯å¦åˆ é™¤åŸæ–‡ä»¶
    print("\nâš ï¸  é‡è¦æç¤ºï¼šæ–‡ä»¶å¤åˆ¶åå¯ä»¥åˆ é™¤åŸæ–‡ä»¶")
    delete_original = input("æ˜¯å¦åœ¨å¤åˆ¶ååˆ é™¤åŸæ–‡ä»¶? (y/n): ").lower() == 'y'
    if delete_original:
        print("âœ… å°†åœ¨å¤åˆ¶ååˆ é™¤åŸæ–‡ä»¶\n")
    else:
        print("âœ… å°†ä¿ç•™åŸæ–‡ä»¶\n")
    
    # åˆ›å»ºåˆ†ç±»ç›®å½•
    for category in DOC_CATEGORIES.keys():
        (docs_dir / category).mkdir(exist_ok=True)
    
    # æŸ¥æ‰¾æ‰€æœ‰ .md æ–‡ä»¶
    md_files = list(project_root.glob("*.md"))
    md_files.extend((project_root / "docs").glob("*.md"))
    
    print(f"\næ‰¾åˆ° {len(md_files)} ä¸ª Markdown æ–‡ä»¶\n")
    
    # åˆ†æå¹¶åˆ†ç±»æ–‡ä»¶
    file_info_list = []
    category_counts = {cat: 0 for cat in DOC_CATEGORIES.keys()}
    
    for md_file in md_files:
        info = analyze_md_file(md_file)
        category = categorize_file(md_file.name)
        info["category"] = category
        category_counts[category] += 1
        file_info_list.append(info)
        
        # å¤åˆ¶æ–‡ä»¶åˆ°å¯¹åº”åˆ†ç±»ç›®å½•
        dest_dir = docs_dir / category
        dest_file = dest_dir / md_file.name
        
        # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ åºå·
        if dest_file.exists():
            base_name = md_file.stem
            ext = md_file.suffix
            counter = 1
            while dest_file.exists():
                dest_file = dest_dir / f"{base_name}_{counter}{ext}"
                counter += 1
        
        shutil.copy2(md_file, dest_file)
        
        # å¦‚æœç”¨æˆ·é€‰æ‹©åˆ é™¤åŸæ–‡ä»¶ï¼Œåˆ™åˆ é™¤
        if delete_original:
            try:
                md_file.unlink()
                print(f"  âœ… {md_file.name} -> {category}/ (å·²åˆ é™¤åŸæ–‡ä»¶)")
            except Exception as e:
                print(f"  âš ï¸  {md_file.name} -> {category}/ (å¤åˆ¶æˆåŠŸï¼Œä½†åˆ é™¤åŸæ–‡ä»¶å¤±è´¥: {e})")
        else:
            print(f"  âœ… {md_file.name} -> {category}/")
    
    # ç”Ÿæˆç´¢å¼•æ–‡ä»¶
    generate_index(docs_dir, file_info_list, category_counts)
    
    # ç”Ÿæˆåˆ†ç±»ç»Ÿè®¡
    generate_summary(docs_dir, file_info_list, category_counts)
    
    print(f"\nâœ… æ–‡æ¡£æ•´ç†å®Œæˆï¼")
    print(f"ğŸ“ æ•´ç†ç›®å½•: {docs_dir}")
    print(f"\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
    for category, count in sorted(category_counts.items()):
        if count > 0:
            print(f"  {category}: {count} ä¸ªæ–‡ä»¶")


def generate_index(docs_dir: Path, file_info_list: List[Dict], category_counts: Dict):
    """ç”Ÿæˆç´¢å¼•æ–‡ä»¶"""
    index_content = """# ğŸ“š é¡¹ç›®æ–‡æ¡£ç´¢å¼•

æœ¬æ–‡æ¡£ç´¢å¼•æä¾›äº†é¡¹ç›®ä¸­æ‰€æœ‰ Markdown æ–‡æ¡£çš„å®Œæ•´åˆ—è¡¨å’Œåˆ†ç±»ã€‚

## ğŸ“Š æ–‡æ¡£ç»Ÿè®¡

"""
    
    total_files = len(file_info_list)
    total_categories = sum(1 for count in category_counts.values() if count > 0)
    
    index_content += f"- **æ€»æ–‡ä»¶æ•°**: {total_files}\n"
    index_content += f"- **åˆ†ç±»æ•°**: {total_categories}\n"
    index_content += f"- **ç”Ÿæˆæ—¶é—´**: {Path(__file__).stat().st_mtime}\n\n"
    
    index_content += "## ğŸ“ åˆ†ç±»ç›®å½•\n\n"
    
    for category in sorted(DOC_CATEGORIES.keys()):
        count = category_counts[category]
        if count == 0:
            continue
        
        category_name = category.replace('_', ' ').replace('0', '').strip()
        index_content += f"### {category_name} ({count} ä¸ªæ–‡ä»¶)\n\n"
        
        files_in_category = [f for f in file_info_list if f["category"] == category]
        for file_info in sorted(files_in_category, key=lambda x: x["name"]):
            title = file_info.get("title", file_info["name"])
            size_kb = file_info["size"] / 1024
            lines = file_info["lines"]
            
            index_content += f"- **[{file_info['name']}]({category}/{file_info['name']})**\n"
            index_content += f"  - æ ‡é¢˜: {title}\n"
            index_content += f"  - å¤§å°: {size_kb:.1f} KB\n"
            index_content += f"  - è¡Œæ•°: {lines}\n"
            if file_info.get("keywords"):
                keywords_str = ", ".join(file_info["keywords"][:5])
                index_content += f"  - å…³é”®è¯: {keywords_str}\n"
            index_content += "\n"
    
    # å†™å…¥ç´¢å¼•æ–‡ä»¶
    index_file = docs_dir / "README.md"
    with open(index_file, 'w', encoding='utf-8') as f:
        f.write(index_content)
    
    print(f"\n  âœ… ç”Ÿæˆç´¢å¼•æ–‡ä»¶: {index_file}")


def generate_summary(docs_dir: Path, file_info_list: List[Dict], category_counts: Dict):
    """ç”Ÿæˆåˆ†ç±»æ‘˜è¦"""
    summary_content = """# ğŸ“‹ æ–‡æ¡£åˆ†ç±»æ‘˜è¦

æœ¬æ–‡æ¡£æä¾›äº†å„åˆ†ç±»çš„ç®€è¦è¯´æ˜å’Œæ–‡ä»¶åˆ—è¡¨ã€‚

"""
    
    category_descriptions = {
        "01_å¿«é€Ÿå¼€å§‹": "å¿«é€Ÿå…¥é—¨æŒ‡å—ï¼Œå¸®åŠ©æ–°ç”¨æˆ·å¿«é€Ÿä¸Šæ‰‹é¡¹ç›®",
        "02_é…ç½®æŒ‡å—": "é…ç½®ç›¸å…³çš„æ–‡æ¡£ï¼ŒåŒ…æ‹¬APIå¯†é’¥ã€ç¯å¢ƒé…ç½®ç­‰",
        "03_æ¶æ„è®¾è®¡": "ç³»ç»Ÿæ¶æ„å’Œè®¾è®¡æ–‡æ¡£",
        "04_å·¥ä½œæµç¨‹": "å·¥ä½œæµç¨‹å’Œç­–ç•¥å¼€å‘æŒ‡å—",
        "05_æ•°æ®ç®¡é“": "æ•°æ®æµè½¬ã€å¤„ç†å’Œè´¨é‡ç›¸å…³çš„æ–‡æ¡£",
        "06_æ—¥å¿—ç³»ç»Ÿ": "æ—¥å¿—è®°å½•å’Œä½¿ç”¨æŒ‡å—",
        "07_å®ç›˜äº¤æ˜“": "å®ç›˜äº¤æ˜“ç›¸å…³çš„æŒ‡å—å’ŒæŠ¥å‘Š",
        "08_æµ‹è¯•éªŒè¯": "æµ‹è¯•å’ŒéªŒè¯ç›¸å…³çš„æ–‡æ¡£",
        "09_é¡¹ç›®æŠ¥å‘Š": "é¡¹ç›®å®ŒæˆæŠ¥å‘Šå’Œæ€»ç»“",
        "10_é—®é¢˜ä¿®å¤": "é—®é¢˜åˆ†æå’Œä¿®å¤æŠ¥å‘Š",
        "11_æ£€æŸ¥æ¸…å•": "å„ç§æ£€æŸ¥æ¸…å•",
        "12_å…¶ä»–": "æœªåˆ†ç±»çš„æ–‡æ¡£",
    }
    
    for category in sorted(DOC_CATEGORIES.keys()):
        count = category_counts[category]
        if count == 0:
            continue
        
        category_name = category.replace('_', ' ').replace('0', '').strip()
        description = category_descriptions.get(category, "æ— æè¿°")
        
        summary_content += f"## {category_name}\n\n"
        summary_content += f"**è¯´æ˜**: {description}\n\n"
        summary_content += f"**æ–‡ä»¶æ•°**: {count}\n\n"
        
        files_in_category = [f for f in file_info_list if f["category"] == category]
        summary_content += "**æ–‡ä»¶åˆ—è¡¨**:\n\n"
        for file_info in sorted(files_in_category, key=lambda x: x["name"]):
            title = file_info.get("title", file_info["name"])
            summary_content += f"- [{file_info['name']}]({category}/{file_info['name']}) - {title}\n"
        
        summary_content += "\n---\n\n"
    
    # å†™å…¥æ‘˜è¦æ–‡ä»¶
    summary_file = docs_dir / "SUMMARY.md"
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(summary_content)
    
    print(f"  âœ… ç”Ÿæˆæ‘˜è¦æ–‡ä»¶: {summary_file}")


if __name__ == "__main__":
    organize_documents()

