"""
数据保存工具模块 - 按日期组织数据文件 (Multi-Agent Refactor)
"""
import os
import json
import pandas as pd
from datetime import datetime
from typing import List, Dict, Optional
from src.utils.logger import log


class DataSaver:
    """数据保存工具类 - 按业务领域和日期自动组织文件
    
    目录结构 (Adversarial Intelligence Framework - AIF):
    data/
      the_oracle/        (数据先知 - DataSync)
      the_strategist/    (量化策略师 - QuantAnalyst)
      the_critic/        (对抗评论员 - DecisionCore)
      the_guardian/      (风控守护者 - RiskAudit)
      the_executor/      (执行指挥官 - ExecutionEngine)
    """
    
    def __init__(self, base_dir: str = 'data'):
        self.base_dir = base_dir
        
        # 定义业务目录映射 (Unified AIF Hierarchy)
        self.dirs = {
            # 1. 采样层 - 数据先知 (The Oracle)
            'market_data': os.path.join(base_dir, 'the_oracle', 'market_data'),
            
            # 2. 假设层 - 量化策略师 (The Strategist)
            'indicators': os.path.join(base_dir, 'the_strategist', 'indicators'),
            'features': os.path.join(base_dir, 'the_strategist', 'features'),
            'analytics': os.path.join(base_dir, 'the_strategist', 'analytics'),
            
            # 3. 对抗层 - 对抗评论员 (The Critic)
            'llm_logs': os.path.join(base_dir, 'the_critic', 'llm_logs'),
            'decisions': os.path.join(base_dir, 'the_critic', 'decisions'),
            
            # 4. 审计层 - 风控守护者 (The Guardian)
            'risk_audits': os.path.join(base_dir, 'the_guardian', 'audits'),
            
            # 5. 执行层 - 执行指挥官 (The Executor)
            'orders': os.path.join(base_dir, 'the_executor', 'orders'),
            'trades': os.path.join(base_dir, 'the_executor', 'trades'),
            'backtest': os.path.join(base_dir, 'the_executor', 'backtests')
        }
        
        # 兼容旧路径映射 (Alias for legacy methods)
        self.dirs['agent_context'] = self.dirs['analytics']
        self.dirs['executions'] = self.dirs['orders']
            
    def _get_date_folder(self, category: str, date: Optional[str] = None) -> str:
        """获取或创建指定类别的日期文件夹"""
        if date is None:
            date = datetime.now().strftime('%Y%m%d')
        
        category_dir = self.dirs.get(category)
        if not category_dir:
            # Fallback for unknown categories
            category_dir = os.path.join(self.base_dir, category)
            os.makedirs(category_dir, exist_ok=True)
            
        date_folder = os.path.join(category_dir, date)
        os.makedirs(date_folder, exist_ok=True)
        return date_folder
    
    def save_market_data(
        self,
        klines: List[Dict],
        symbol: str,
        timeframe: str,
        save_formats: List[str] = ['json', 'csv', 'parquet']
    ) -> Dict[str, str]:
        """保存原始K线数据 (原 save_step1_klines)"""
        if not klines:
            log.warning("K线数据为空，跳过保存")
            return {}
        
        date_folder = self._get_date_folder('market_data')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # 元数据
        df = pd.DataFrame(klines)
        try:
            first_ts = pd.to_datetime(klines[0]['timestamp'], unit='ms')
            last_ts = pd.to_datetime(klines[-1]['timestamp'], unit='ms')
        except:
            first_ts = "unknown"
            last_ts = "unknown"
            
        metadata = {
            'symbol': symbol,
            'timeframe': timeframe,
            'count': len(klines),
            'timestamp': timestamp
        }
        
        saved_files = {}
        filename_base = f'market_data_{symbol}_{timeframe}_{timestamp}'
        
        if 'json' in save_formats:
            path = os.path.join(date_folder, f'{filename_base}.json')
            with open(path, 'w', encoding='utf-8') as f:
                json.dump({'metadata': metadata, 'klines': klines}, f, indent=2)
            saved_files['json'] = path
            
        if 'csv' in save_formats:
            path = os.path.join(date_folder, f'{filename_base}.csv')
            df.to_csv(path, index=False)
            saved_files['csv'] = path
            
        if 'parquet' in save_formats:
            path = os.path.join(date_folder, f'{filename_base}.parquet')
            df.to_parquet(path, index=False)
            saved_files['parquet'] = path
            
        log.debug(f"保存市场数据: {symbol} {timeframe}")
        return saved_files

    def save_indicators(
        self,
        df: pd.DataFrame,
        symbol: str,
        timeframe: str,
        snapshot_id: str
    ) -> Dict[str, str]:
        """保存技术指标数据 (原 save_step2_indicators)"""
        date_folder = self._get_date_folder('indicators')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        filename = f'indicators_{symbol}_{timeframe}_{timestamp}_{snapshot_id}.parquet'
        path = os.path.join(date_folder, filename)
        
        df.to_parquet(path)
        log.debug(f"保存技术指标: {path}")
        return {'parquet': path}

    def save_features(
        self,
        features: pd.DataFrame,
        symbol: str,
        timeframe: str,
        snapshot_id: str,
        version: str = 'v1'
    ) -> Dict[str, str]:
        """保存特征数据 (原 save_step3_features)"""
        date_folder = self._get_date_folder('features')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        filename = f'features_{symbol}_{timeframe}_{timestamp}_{snapshot_id}_{version}.parquet'
        path = os.path.join(date_folder, filename)
        
        features.to_parquet(path)
        log.debug(f"保存特征数据: {path}")
        return {'parquet': path}

    def save_context(
        self,
        context: Dict,
        symbol: str,
        identifier: str,
        snapshot_id: str
    ) -> Dict[str, str]:
        """保存Agent上下文/分析结果 (原 save_step4_context)"""
        date_folder = self._get_date_folder('agent_context')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        filename = f'context_{symbol}_{identifier}_{timestamp}_{snapshot_id}.json'
        path = os.path.join(date_folder, filename)
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(context, f, indent=2, ensure_ascii=False)
            
        log.debug(f"保存Agent上下文: {path}")
        return {'json': path}

    def save_llm_log(
        self,
        content: str,
        symbol: str,
        snapshot_id: str
    ) -> Dict[str, str]:
        """保存LLM交互日志 (原 save_step5_markdown)"""
        date_folder = self._get_date_folder('llm_logs')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        filename = f'llm_log_{symbol}_{timestamp}_{snapshot_id}.md'
        path = os.path.join(date_folder, filename)
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
            
        log.debug(f"保存LLM日志: {path}")
        return {'md': path}

    def save_decision(
        self,
        decision: Dict,
        symbol: str,
        snapshot_id: str
    ) -> Dict[str, str]:
        """保存决策结果 (原 save_step6_decision)"""
        date_folder = self._get_date_folder('decisions')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        filename = f'decision_{symbol}_{timestamp}_{snapshot_id}.json'
        path = os.path.join(date_folder, filename)
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(decision, f, indent=2, ensure_ascii=False)
            
        log.debug(f"保存决策结果: {path}")
        return {'json': path}

    def save_execution(
        self,
        record: Dict,
        symbol: str
    ) -> Dict[str, str]:
        """保存执行记录"""
        date_folder = self._get_date_folder('orders')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        filename = f'order_{symbol}_{timestamp}.json'
        path = os.path.join(date_folder, filename)
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(record, f, indent=2, ensure_ascii=False)
        
        # 追加CSV
        csv_path = os.path.join(date_folder, f'orders_{symbol}.csv')
        df = pd.DataFrame([record])
        if os.path.exists(csv_path):
            df.to_csv(csv_path, mode='a', header=False, index=False)
        else:
            df.to_csv(csv_path, index=False)
            
        log.debug(f"保存执行记录: {path}")
        return {'json': path, 'csv': csv_path}

    def save_risk_audit(
        self,
        audit_result: Dict,
        symbol: str,
        snapshot_id: str
    ) -> Dict[str, str]:
        """保存风控审计结果"""
        date_folder = self._get_date_folder('risk_audits')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        filename = f'audit_{symbol}_{timestamp}_{snapshot_id}.json'
        path = os.path.join(date_folder, filename)
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(audit_result, f, indent=2, ensure_ascii=False)
            
        log.debug(f"保存风控审计记录: {path}")
        return {'json': path}

    def list_files(self, category: str, date: str = None) -> List[str]:
        """列出文件"""
        folder = self._get_date_folder(category, date)
        if not os.path.exists(folder):
            return []
        return [os.path.join(folder, f) for f in os.listdir(folder)]

    # 兼容性别名 (Adapters for old code if any remains)
    save_step1_klines = save_market_data
    save_step2_indicators = save_indicators
    save_step3_features = save_features
    save_step4_context = save_context
    save_step5_markdown = save_llm_log
    save_step6_decision = save_decision
    save_step7_execution = save_execution

    # --- 交易历史记录扩展 ---
    TRADE_COLUMNS = [
        'record_time', 'action', 'symbol', 'price', 'quantity', 
        'cost', 'exit_price', 'pnl', 'confidence', 'status'
    ]

    def save_trade(self, trade_data: Dict):
        """保存交易记录（持久化追加至单一CSV，标准化 Schema）"""
        try:
            category = 'trades'
            base_path = self.dirs.get(category)
            if not os.path.exists(base_path):
                os.makedirs(base_path, exist_ok=True)
            
            file_path = os.path.join(base_path, 'all_trades.csv')
            
            # 1. 完善基础字段
            trade_data['record_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            # 2. 补全缺失字段 (Schema 稳定性)
            for col in self.TRADE_COLUMNS:
                if col not in trade_data:
                    trade_data[col] = 0.0 if col in ['cost', 'pnl', 'exit_price', 'price', 'quantity'] else 'N/A'
            
            # 3. 按标准顺序转换为 DataFrame
            df = pd.DataFrame([{col: trade_data[col] for col in self.TRADE_COLUMNS}])
            
            # 4. 保存
            if os.path.exists(file_path):
                df.to_csv(file_path, mode='a', header=False, index=False)
            else:
                df.to_csv(file_path, mode='w', header=True, index=False)
            
            log.debug(f"交易记录已保存 (标准化): {file_path}")
        except Exception as e:
            log.error(f"保存标准化交易记录失败: {e}")

    def get_recent_trades(self, limit: int = 10) -> List[Dict]:
        """获取最近的交易记录"""
        try:
            file_path = os.path.join(self.dirs.get('trades'), 'all_trades.csv')
            if not os.path.exists(file_path):
                return []
            
            df = pd.read_csv(file_path)
            # 获取最后N条并按时间反序（或者保持原序由展示层决定）
            recent = df.tail(limit).to_dict('records')
            return recent
        except Exception as e:
            log.error(f"获取最近交易记录失败: {e}")
            return []
